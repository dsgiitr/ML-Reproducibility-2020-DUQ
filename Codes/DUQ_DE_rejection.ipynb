{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DUQ_DE_rejection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NdrkVE3JhPt",
        "outputId": "bae4528c-dc6b-42cd-ccd2-b36f478fe39d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31kViAtB9PEe"
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from utils.cnn_duq import CNN_DUQ\n",
        "from utils.datasets import all_datasets\n",
        "from utils.cnn_duq import SoftmaxModel as CNN\n",
        "\n",
        "from utils.resnet import ResNet\n",
        "from utils.resnet_duq import ResNet_DUQ\n",
        "from utils.evaluate_ood import get_cifar_svhn_ood, get_auroc_classification\n",
        "\n",
        "mod='CIFAR10' #['CIFAR10','FMnist']\n",
        "\n",
        "if mod=='FMnist':\n",
        "    ds1 = all_datasets[\"FashionMNIST\"]()\n",
        "    ds2 = all_datasets[\"MNIST\"]()\n",
        "    input_size = 28\n",
        "    num_classes = 10\n",
        "    embedding_size = 256\n",
        "    learnable_length_scale = False\n",
        "    gamma = 0.999\n",
        "    length_scale = 0.1\n",
        "    d=28\n",
        "    c=1\n",
        "\n",
        "    model = CNN_DUQ(\n",
        "    input_size,\n",
        "    num_classes,\n",
        "    embedding_size,\n",
        "    learnable_length_scale,\n",
        "    length_scale,\n",
        "    gamma,\n",
        "    )\n",
        "    #model.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/DUQ_FM_30_FULL.pt'))\n",
        "\n",
        "    ensemble = [CNN(input_size, num_classes).cuda() for _ in range(5)]\n",
        "    ensemble = torch.nn.ModuleList(ensemble);\n",
        "    #ensemble.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/FM_5_ensemble_30.pt'))\n",
        "\n",
        "else:\n",
        "    ds1 = all_datasets[\"CIFAR10\"]()\n",
        "    ds2 = all_datasets[\"SVHN\"]()\n",
        "    length_scale = 0.1\n",
        "    input_size, num_classes, dataset, test_dataset = ds1\n",
        "    centroid_size=512\n",
        "    model_output_size=512 \n",
        "    gamma = 0.999\n",
        "    d=32\n",
        "    c=3\n",
        "\n",
        "    model = ResNet_DUQ(\n",
        "            input_size, num_classes, centroid_size, model_output_size, length_scale, gamma\n",
        "        )\n",
        "    model.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/DUQ_CIFAR_75.pt'))\n",
        "    ensemble = [\n",
        "            ResNet(input_size, num_classes).cuda() for _ in range(5)\n",
        "        ]\n",
        "    ensemble = torch.nn.ModuleList(ensemble);\n",
        "    ensemble.load_state_dict(torch.load('/content/gdrive/My Drive/Colab Notebooks/CIFAR10_5_ensemble.pt'))\n",
        "    \n",
        "model.eval()\n",
        "ensemble.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT-7TDRzBwAa"
      },
      "source": [
        "args={'ensemble':5}\n",
        "input_size, num_classes, _ , test_dataset_n = ds1\n",
        "_ , _ , _ , test_dataset_o = ds2\n",
        "\n",
        "test_dataset_o.target_transform = lambda id: 100   #MNIST to be considered all wrong \n",
        "\"\"\"Data=[]\n",
        "for i in range(200,500):\n",
        "    Data.append(test_dataset_o[i])\n",
        "    Data.append(test_dataset_n[i])\"\"\"\n",
        "Data = test_dataset_n + test_dataset_o\n",
        "num=len(Data)\n",
        "rejection_list = [0.1 , 0.2 , 0.3 ,0.4 , 0.5 ,0.6 , 0.7 , 0.8 , 0.9]\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BPrLKFCBz4O"
      },
      "source": [
        "target = np.zeros((Data.__len__(),))\n",
        "\n",
        "confidence_DUQ = np.zeros((Data.__len__(),))\n",
        "pred_DUQ = np.zeros((Data.__len__(),))\n",
        "d=32\n",
        "c=3\n",
        "\n",
        "for i in range(len(Data)):\n",
        "  with torch.no_grad():\n",
        "    _ , output = model((Data[i][0]).reshape(1,c,d,d))\n",
        "    target[i] = Data[i][1]\n",
        "    confidence_DUQ[i] , pred_DUQ[i]= output.max(1)\n",
        "    if(i%500==0):\n",
        "      print(i)\n",
        "\n",
        "a  = np.concatenate((target.reshape(-1,1),pred_DUQ.reshape(-1,1),confidence_DUQ.reshape(-1,1)) , axis=1)\n",
        "x  = a[a[:,-1].argsort()]\n",
        "\n",
        "accuracy_DUQ = np.zeros((len(rejection_list),1))\n",
        "rejected_DUQ = np.zeros((len(rejection_list),1))\n",
        "i=0\n",
        "for reject in rejection_list :\n",
        "  y = x[:][int(reject*num):]\n",
        "  accuracy_DUQ[i] = ((y[:,0]==y[:,1]).sum())/((1-reject)*num)\n",
        "  rejected_DUQ[i] = reject*100\n",
        "  i+=1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIcJ4uwaB3qf"
      },
      "source": [
        "confidence_DE = np.zeros((Data.__len__(),))\n",
        "pred_DE = np.zeros((Data.__len__(),))\n",
        "\n",
        "for i in range(len(Data)):\n",
        "  with torch.no_grad():\n",
        "      predictions = torch.stack([model(Data[i][0].reshape(1,c,d,d).cuda()) for model in ensemble])\n",
        "      mean_prediction = torch.mean(predictions.exp(), dim=0)\n",
        "      pred_DE[i] = mean_prediction.max(1)[1]\n",
        "      target[i] = Data[i][1]\n",
        "      confidence_DE[i] = torch.sum(mean_prediction * torch.log(mean_prediction), dim=1)\n",
        "      if(i%500==0):\n",
        "          print(i)\n",
        "\n",
        "a  = np.concatenate((target.reshape(-1,1),pred_DE.reshape(-1,1),confidence_DE.reshape(-1,1)) , axis=1)\n",
        "x  = a[a[:,-1].argsort()]\n",
        "\n",
        "accuracy_DE = np.zeros((len(rejection_list),1))\n",
        "rejected_DE = np.zeros((len(rejection_list),1))\n",
        "\n",
        "i=0\n",
        "for reject in rejection_list :\n",
        "  y = x[:][int(reject*num):]\n",
        "  accuracy_DE[i] = ((y[:,0]==y[:,1]).sum())/((1-reject)*num) \n",
        "  rejected_DE[i] = reject*100\n",
        "  i+=1\n",
        "\n",
        "plt.plot(rejected_DUQ, accuracy_DUQ, color='blue', linewidth = 2, \n",
        "         marker='o', markerfacecolor='blue', markersize=5 , label='DUQ')\n",
        "plt.plot(rejected_DE , accuracy_DE , color='orange', linewidth = 2, \n",
        "         marker='o', markerfacecolor='orange', markersize=5 , label='5-Deep Ensemble')\n",
        "\n",
        "\n",
        "\n",
        "plt.ylim(0.4,1.01) \n",
        "plt.xlim(0,100) \n",
        "\n",
        "plt.xlabel('Percent of data rejected by uncertainity') \n",
        "plt.ylabel('Accuracy') \n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}