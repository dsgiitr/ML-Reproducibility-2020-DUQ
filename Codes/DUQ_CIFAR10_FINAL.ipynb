{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome to Colaboratory",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuXCQuKqL6w6"
      },
      "source": [
        "import argparse\n",
        "import json\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "!pip install pytorch-ignite\n",
        "from ignite.engine import Events, Engine\n",
        "from ignite.metrics import Accuracy, Average, Loss\n",
        "from ignite.contrib.handlers import ProgressBar\n",
        "\n",
        "from utils.resnet_duq import ResNet_DUQ\n",
        "from utils.datasets import all_datasets\n",
        "from utils.evaluate_ood import get_cifar_svhn_ood, get_auroc_classification\n",
        "\n",
        "model={}\n",
        "def main(\n",
        "    batch_size,\n",
        "    epochs,\n",
        "    length_scale,\n",
        "    centroid_size,\n",
        "    model_output_size,\n",
        "    learning_rate,\n",
        "    l_gradient_penalty,\n",
        "    gamma,\n",
        "    weight_decay,\n",
        "    final_model,\n",
        "):\n",
        "    name = f\"DUQ_{length_scale}__{l_gradient_penalty}_{gamma}_{centroid_size}\"\n",
        "    writer = SummaryWriter(comment=name)\n",
        "\n",
        "    ds = all_datasets[\"CIFAR10\"]()\n",
        "    input_size, num_classes, dataset, test_dataset = ds\n",
        "\n",
        "    # Split up training set\n",
        "    idx = list(range(len(dataset)))\n",
        "    random.shuffle(idx)\n",
        "\n",
        "    if final_model:\n",
        "        train_dataset = dataset\n",
        "        val_dataset = test_dataset\n",
        "    else:\n",
        "        val_size = int(len(dataset) * 0.8)\n",
        "        train_dataset = torch.utils.data.Subset(dataset, idx[:val_size])\n",
        "        val_dataset = torch.utils.data.Subset(dataset, idx[val_size:])\n",
        "\n",
        "        val_dataset.transform = (\n",
        "            test_dataset.transform\n",
        "        )  # Test time preprocessing for validation\n",
        "    global model\n",
        "    model = ResNet_DUQ(\n",
        "        input_size, num_classes, centroid_size, model_output_size, length_scale, gamma\n",
        "    )\n",
        "    model = model.cuda()\n",
        "\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "        optimizer, milestones=[25, 50, 75], gamma=0.2\n",
        "    )\n",
        "\n",
        "    def bce_loss_fn(y_pred, y):\n",
        "        bce = F.binary_cross_entropy(y_pred, y, reduction=\"sum\").div(\n",
        "            num_classes * y_pred.shape[0]\n",
        "        )\n",
        "        return bce\n",
        "\n",
        "    def output_transform_bce(output):\n",
        "        y_pred, y, x = output\n",
        "\n",
        "        y = F.one_hot(y, num_classes).float()\n",
        "\n",
        "        return y_pred, y\n",
        "\n",
        "    def output_transform_acc(output):\n",
        "        y_pred, y, x = output\n",
        "\n",
        "        return y_pred, y\n",
        "\n",
        "    def output_transform_gp(output):\n",
        "        y_pred, y, x = output\n",
        "\n",
        "        return x, y_pred\n",
        "\n",
        "    def calc_gradients_input(x, y_pred):\n",
        "        gradients = torch.autograd.grad(\n",
        "            outputs=y_pred,\n",
        "            inputs=x,\n",
        "            grad_outputs=torch.ones_like(y_pred),\n",
        "            create_graph=True,\n",
        "        )[0]\n",
        "\n",
        "        gradients = gradients.flatten(start_dim=1)\n",
        "\n",
        "        return gradients\n",
        "\n",
        "    def calc_gradient_penalty(x, y_pred):\n",
        "        gradients = calc_gradients_input(x, y_pred)\n",
        "\n",
        "        # L2 norm\n",
        "        grad_norm = gradients.norm(2, dim=1)\n",
        "\n",
        "        # Two sided penalty\n",
        "        gradient_penalty = ((grad_norm - 1) ** 2).mean()\n",
        "\n",
        "        return gradient_penalty\n",
        "\n",
        "    def step(engine, batch):\n",
        "        model.train()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y = batch\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        if l_gradient_penalty > 0:\n",
        "            x.requires_grad_(True)\n",
        "\n",
        "        z, y_pred = model(x)\n",
        "        y = F.one_hot(y, num_classes).float()\n",
        "\n",
        "        loss = bce_loss_fn(y_pred, y)\n",
        "\n",
        "        if l_gradient_penalty > 0:\n",
        "            loss += l_gradient_penalty * calc_gradient_penalty(x, y_pred)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        x.requires_grad_(False)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            model.update_embeddings(x, y)\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    def eval_step(engine, batch):\n",
        "        model.eval()\n",
        "\n",
        "        x, y = batch\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        x.requires_grad_(True)\n",
        "\n",
        "        z, y_pred = model(x)\n",
        "\n",
        "        return y_pred, y, x\n",
        "\n",
        "    trainer = Engine(step)\n",
        "    evaluator = Engine(eval_step)\n",
        "\n",
        "    metric = Average()\n",
        "    metric.attach(trainer, \"loss\")\n",
        "\n",
        "    metric = Accuracy(output_transform=output_transform_acc)\n",
        "    metric.attach(evaluator, \"accuracy\")\n",
        "\n",
        "    metric = Loss(F.binary_cross_entropy, output_transform=output_transform_bce)\n",
        "    metric.attach(evaluator, \"bce\")\n",
        "\n",
        "    metric = Loss(calc_gradient_penalty, output_transform=output_transform_gp)\n",
        "    metric.attach(evaluator, \"gradient_penalty\")\n",
        "\n",
        "    kwargs = {\"num_workers\": 4, \"pin_memory\": True}\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs\n",
        "    )\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset, batch_size=1000, shuffle=False, **kwargs\n",
        "    )\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=1000, shuffle=False, **kwargs\n",
        "    )\n",
        "\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_results(trainer):\n",
        "        metrics = trainer.state.metrics\n",
        "        loss = metrics[\"loss\"]\n",
        "\n",
        "        print(f\"Train - Epoch: {trainer.state.epoch} Loss: {loss:.2f} \")\n",
        "\n",
        "        writer.add_scalar(\"Loss/train\", loss, trainer.state.epoch)\n",
        "\n",
        "        if trainer.state.epoch % 5 == 0 or trainer.state.epoch > 65:\n",
        "            accuracy, auroc = get_cifar_svhn_ood(model)\n",
        "            print(f\"Test Accuracy: {accuracy}, AUROC: {auroc}\")\n",
        "            writer.add_scalar(\"OoD/test_accuracy\", accuracy, trainer.state.epoch)\n",
        "            writer.add_scalar(\"OoD/roc_auc\", auroc, trainer.state.epoch)\n",
        "\n",
        "            accuracy, auroc = get_auroc_classification(val_dataset, model)\n",
        "            print(f\"AUROC - uncertainty: {auroc}\")\n",
        "            writer.add_scalar(\"OoD/val_accuracy\", accuracy, trainer.state.epoch)\n",
        "            writer.add_scalar(\"OoD/roc_auc_classification\", auroc, trainer.state.epoch)\n",
        "\n",
        "        evaluator.run(val_loader)\n",
        "        metrics = evaluator.state.metrics\n",
        "        acc = metrics[\"accuracy\"]\n",
        "        bce = metrics[\"bce\"]\n",
        "        GP = metrics[\"gradient_penalty\"]\n",
        "        loss = bce + l_gradient_penalty * GP\n",
        "\n",
        "        print(\n",
        "            (\n",
        "                f\"Valid - Epoch: {trainer.state.epoch} \"\n",
        "                f\"Acc: {acc:.4f} \"\n",
        "                f\"Loss: {loss:.2f} \"\n",
        "                f\"BCE: {bce:.2f} \"\n",
        "                f\"GP: {GP:.2f} \"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        writer.add_scalar(\"Loss/valid\", loss, trainer.state.epoch)\n",
        "        writer.add_scalar(\"BCE/valid\", bce, trainer.state.epoch)\n",
        "        writer.add_scalar(\"GP/valid\", GP, trainer.state.epoch)\n",
        "        writer.add_scalar(\"Accuracy/valid\", acc, trainer.state.epoch)\n",
        "\n",
        "        print(f\"Centroid norm: {torch.norm(model.m / model.N, dim=0)}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if trainer.state.epoch > 65:\n",
        "            torch.save(\n",
        "                model.state_dict(), f\"saved_models/{name}_{trainer.state.epoch}.pt\"\n",
        "            )\n",
        "\n",
        "    pbar = ProgressBar(dynamic_ncols=True)\n",
        "    pbar.attach(trainer)\n",
        "\n",
        "    trainer.run(train_loader, max_epochs=epochs)\n",
        "\n",
        "    evaluator.run(test_loader)\n",
        "    acc = evaluator.state.metrics[\"accuracy\"]\n",
        "\n",
        "    print(f\"Test - Accuracy {acc:.4f}\")\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(128,75,0.1,512,512,0.05,0.5,0.999,5e-4,False)\n",
        "    torch.save(model.state_dict(), \"DUQ_CIFAR_75.pt\")\n",
        "    #model.load_state_dict(torch.load(\"C:/Users/Rohan/Documents/Misc/superhd1.pt\"))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}